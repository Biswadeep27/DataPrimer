Apache Spark is a fast and general-purpose cluster computing system. It provides high-level APIs in Java, Scala, Python and R, 
and an optimized engine that supports general execution graphs. It also supports a rich set of higher-level tools including 
Spark SQL for SQL and structured data processing, MLlib for machine learning, GraphX for graph processing, and Spark Streaming.


Nodes in Hadoop:
-------------------

There are three kind of nodes :

The masters are the nodes that host the core more-unique Hadoop roles that usually orchestrate/coordinate/oversee processes 
and roles on the other nodes — think HDFS NameNodes (of which max there can only be 2), Hive Metastore Server (only one at the 
time of writing this answer), YARN ResourceManager (just the one), HBase Masters, Impala StateStore and Catalog Server (one 
of each). All master roles need not necessarily have a fixed number of instances (you can have many Zookeeper Servers) but they 
all have associated roles within the same service that rely on them to function. A typical enterprise production cluster has 2–3 
master nodes, scaling up as per size and services installed on the cluster.


Contrary to this, the workers are the actual nodes doing the real work of storing data or performing compute or other operations. 
Roles like HDFS DataNode, YARN NodeManager, HBase RegionServer, Impala Daemons etc — they need the master roles to coordinate the 
work and total instances of each of these roles usually scale more linearly with the size of the cluster. A typical cluster has 
about 80-90% nodes dedicated to hosting worker roles.


Put simply, edge nodes are the nodes that are neither masters, nor workers. They usually act as gateways/connection-portals for 
end-users to reach the worker nodes better. Roles like HiveServer2 servers, Impala LoadBalancer (Proxy server for Impala Daemons), 
Flume agents, config files and web interfaces like HttpFS, Oozie servers, Hue servers etc — they all fall under this category. 
Most of each of these roles can be installed on multiple nodes (assigning more nodes for each role helps prevent everybody from 
connecting to one instance and overwhelming that node).


The purpose of introducing edge nodes as against direct worker node access is: one — they act as network interface for the cluster 
and outside world (you don’t want to leave the entire cluster open to the outside world when you can make do with a few nodes 
instead. This also helps keep the network architecture costs low); two — uniform data/work distribution (users directly connecting 
to the same set of few worker nodes won’t harness the entire cluster’s resources resulting in data skew/performance issues); and 
three — edge nodes serve as staging space for final data (stuff like data ingest using Sqoop, Oozie workflow setup etc).



Node = any physical host that belongs to your cluster


Services = HDFS, Hive, Impala, Zookeeper etc → they are installed on nodes

Now, NameNode is a role for HDFS service that must be installed on a node (or on two nodes if you need active and secondary nodes 
to ensure availability), just like all the other Hadoop service roles need to be installed on the cluster nodes. The node on 
which NameNode is installed then goes on to be known as the master node for the cluster. Since a cluster can have multiple master 
nodes (all of which may not necessarily have the role NameNode running on them), therefore sometimes nodes are addressed by the 
roles themselves to identify the right host(s) and so the master node on which the NameNode role is installed becomes known as the 
Name Node. NameNode itself is nothing but a directory listing/tracker of HDFS data that exists on the Data Nodes i.e. nodes on 
which HDFS DataNode role is installed. From a cluster architecture standpoint, data nodes are usually the worker nodes of the 
cluster.




Spark applications run as independent sets of processes on a cluster, coordinated by the SparkContext object in your main program 
(called the driver program).

Specifically, to run on a cluster, the SparkContext can connect to several types of cluster managers (either Spark’s own 
standalone cluster manager, Mesos or YARN), which allocate resources across applications. Once connected, Spark acquires 
executors on nodes in the cluster, which are processes that run computations and store data for your application. Next, 
it sends your application code (defined by JAR or Python files passed to SparkContext) to the executors. Finally, SparkContext 
sends tasks to the executors to run.



sparkSession:
The entry point into all functionality in Spark is the SparkSession class. To create a basic SparkSession, just use 
SparkSession.builder():



yarn logs -applicationId <app ID>

There are two deploy modes that can be used to launch Spark applications on YARN. In cluster mode, the Spark driver runs inside 
an application master process which is managed by YARN on the cluster, and the client can go away after initiating the application. 
In client mode, the driver runs in the client process, and the application master is only used for requesting resources from YARN.

Unlike other cluster managers supported by Spark in which the master’s address is specified in the --master parameter, in YARN 
mode the ResourceManager’s address is picked up from the Hadoop configuration. Thus, the --master parameter is yarn.

--class: The entry point for your application (e.g. org.apache.spark.examples.SparkPi)
--master: The master URL for the cluster (e.g. spark://23.195.26.187:7077)
--deploy-mode: Whether to deploy your driver on the worker nodes (cluster) or locally as an external client (client) 
(default: client) †
--conf: Arbitrary Spark configuration property in key=value format. For values that contain spaces wrap “key=value” in quotes 
(as shown).
application-jar: Path to a bundled jar including your application and all dependencies. The URL must be globally visible inside of 
your cluster, for instance, an hdfs:// path or a file:// path that is present on all nodes.
application-arguments: Arguments passed to the main method of your main class, if any



† A common deployment strategy is to submit your application from a gateway machine that is physically co-located with your worker 
machines (e.g. Master node in a standalone EC2 cluster). In this setup, client mode is appropriate. In client mode, the driver is 
launched directly within the spark-submit process which acts as a client to the cluster. The input and output of the application 
is attached to the console. Thus, this mode is especially suitable for applications that involve the REPL (e.g. Spark shell).



Alternatively, if your application is submitted from a machine far from the worker machines (e.g. locally on your laptop), it is 
common to use cluster mode to minimize network latency between the drivers and the executors. Currently, the standalone mode does 
not support cluster mode for Python applications.







spark : a Definitive guide:
===============================

Narrow transformation — In Narrow transformation, all the elements that are required to compute the records in single partition live in the single partition of parent RDD. A limited subset of partition is used to calculate the result. Narrow transformations are the result of map(), filter().

Wide transformation — In wide transformation, all the elements that are required to compute the records in the single partition may live in many partitions of parent RDD. The partition may live in many partitions of parent RDD. Wide transformations are the result of groupbyKey and reducebyKey.


Actions
Transformations create RDDs from each other, but when we want to work with the actual dataset, at that point action is performed. When the action is triggered after the result, new RDD is not formed like transformation. Thus, actions are RDD operations that give non-RDD values. The values of action are stored to drivers or to the external storage system. It brings laziness of RDD into motion.
Spark drivers and external storage system store the value of action. It brings laziness of RDD into motion.

An action is one of the ways of sending data from Executer to the driver. Executors are agents that are responsible for executing a task. While the driver is a JVM process that coordinates workers and execution of the task.

Spark workflow:
-----------------

STEP 1: The client submits spark user application code. When an application code is submitted, the driver implicitly converts user code that contains transformations and actions into a logically directed acyclic graph called DAG. At this stage, it also performs optimizations such as pipelining transformations.

STEP 2: After that, it converts the logical graph called DAG into physical execution plan with many stages. After converting into a physical execution plan, it creates physical execution units called tasks under each stage. Then the tasks are bundled and sent to the cluster.

STEP 3: Now the driver talks to the cluster manager and negotiates the resources. Cluster manager launches executors in worker nodes on behalf of the driver. At this point, the driver will send the tasks to the executors based on data placement. When executors start, they register themselves with drivers. So, the driver will have a complete view of executors that are executing the task.

STEP 4: During the course of execution of tasks, driver program will monitor the set of executors that runs. Driver node also schedules future tasks based on data placement. 


transformation-> action -> job -> stage -> task

1. Application : It could be single command or combination of commands with complex logic. When code is submitted to spark for execution, the application kicks off.

2. Job : When an application is submitted to spark, driver process converts the code  into job.

3. Stage : Jobs are divided into stages. If the application code demands shuffling data accross nodes, new stage is created. Number of stages are determined by the 
number of shuffling operation.

4. Task : Stages are further divided into multiple tasks, In a stage, all the tasks would execute same logic. Each task would process one partition at a time. So number of partition in the distributed cluster, would determine the number of task at each stage.

1 task = 1 slot = 1 core =  1 partition (Physical execution unit)

Executor Memory :

for a 32 GB RAM(On-Heap Memory) on each executor ->

~300 MB -> Reserved Memory
40 % ~ 13 GB -> User memory -> to store metadata and other objects 
60 % ~ 19 GB -> Unified Memory

Unified Memory = 50% Storage Memory (Partitons/persist) + 50 % Execution/Processing Memory (by default but can be configured.)


Executors  have off-heap memory as well (Disks)



f"{str(((h+(d//60))%24) + ((m + (d%60))//60))}:{str(((m + (d%60))%60))}"


==============================
Spark Joining strategies:
------

1. Hash Join: Hash Join is performed by first creating a Hash Table based on join_key of smaller relation and then looping over larger relation to match the hashed join_key values. Also, this is only supported for ‘=’ join. In spark, Hash Join plays a role at per node level and the strategy is used to join partitions available on the node.

2. Broadcast Hash Join: In broadcast hash join, copy of one of the join relations are being sent to all the worker nodes and it saves shuffling cost. This is useful when you are joining a large relation with a smaller one. It is also known as map-side join(associating worker nodes with mappers).

Spark deploys this join strategy when the size of one of the join relations is less than the threshold values(default 10 M). The spark property which defines this threshold is spark.sql.autoBroadcastJoinThreshold(configurable).

Things to Note:

#The broadcasted relation should fit completely into the memory of each executor as well as the driver. In Driver, because driver will start the data transfer.
#Only supported for ‘=’ join.
#Supported for all join types(inner, left, right) except full outer joins.
#When the broadcast size is small, it is usually faster than other join strategies.
#Copy of relation is broadcasted over the network. Therefore, being a network-intensive operation could cause out of memory errors or performance issues when broadcast size is big(for instance, when explicitly specified to use broadcast join/changes in the default threshold)
#You can’t make changes to the broadcasted relation, after broadcast. Even if you do, they won’t be available to the worker nodes(because the copy is already shipped).


3. Shuffle hash join: Shuffle Hash Join involves moving data with the same value of join key in the same executor node followed by Hash Join(explained above). Using the join condition as output key, data is shuffled amongst executor nodes and in the last step, data is combined using Hash Join, as we know data of the same key will be present in the same executor. (= joins except full outer join)

4. Shuffle sort-merge join: Sort join involves, first sorting the relations based on join keys and then merging both the datasets(think of merge step of merge sort).

Shuffle sort-merge join involves, shuffling of data to get the same join_key with the same worker, and then performing sort-merge join operation at the partition level in the worker nodes. (all = joins)

5. Cartesian Join: In this strategy, the cartesian product(similar to SQL) of the two relations is calculated to evaluate join.

6. Broadcast nested loop join : Think of this as a nested loop comparison of both the relations. As you can see, this can be a very slow strategy. This is generally, a fallback option when no other join type can be applied. Spark handles this using BroadcastNestedLoopJoinExec operator that broadcasts the appropriate side of the query, so you can think that at least some chunk of results will be broadcasted to improve performance. (all joins i.e = > < >= <=)


How spark selects join strategy?
--
If it is an ‘=’ join:
Look at the join hints, in the following order:
1. Broadcast Hint: Pick broadcast hash join if the join type is supported.
2. Sort merge hint: Pick sort-merge join if join keys are sortable.
3. shuffle hash hint: Pick shuffle hash join if the join type is supported.
4. shuffle replicate NL hint: pick cartesian product if join type is inner like.

If there is no hint or the hints are not applicable
1. Pick broadcast hash join if one side is small enough to broadcast, and the join type is supported.
2. Pick shuffle hash join if one side is small enough to build the local hash map, and is much smaller than the other side, and spark.sql.join.preferSortMergeJoin is false.
3. Pick sort-merge join if join keys are sortable.
4. Pick cartesian product if join type is inner .
5. Pick broadcast nested loop join as the final solution. It may OOM but there is no other choice.

If it’s not ‘=’ join:
Look at the join hints, in the following order:
1. broadcast hint: pick broadcast nested loop join.
2. shuffle replicate NL hint: pick cartesian product if join type is inner like.

If there is no hint or the hints are not applicable
1. Pick broadcast nested loop join if one side is small enough to broadcast.
2. Pick cartesian product if join type is inner like.
3. Pick broadcast nested loop join as the final solution. It may OOM but we don’t have any other choice.


Hardware Provisioning:
=========================

A. Storage Systems : Because most Spark jobs will likely have to read input data from an external storage system (e.g. the Hadoop File System, or HBase), it is important to place it as close to this system as possible. We recommend the following:

- If at all possible, run Spark on the same nodes as HDFS. Alternatively, you can run Hadoop and Spark on a common cluster manager like Mesos or Hadoop YARN.
- If this is not possible, run Spark on different nodes in the same local-area network as HDFS.
- For low-latency data stores like HBase, it may be preferable to run computing jobs on different nodes than the storage system to avoid interference.

B. Local Disks: While Spark can perform a lot of its computation in memory, it still uses local disks to store data that doesn’t fit in RAM, as well as to preserve intermediate output between stages. We recommend having 4-8 disks per node, configured without RAID (just as separate mount points).

C. Memory: In general, Spark can run well with anywhere from 8 GiB to hundreds of gigabytes of memory per machine. In all cases, we recommend allocating only at most 75% of the memory for Spark; leave the rest for the operating system and buffer cache. 

Finally, note that the Java VM does not always behave well with more than 200 GiB of RAM. If you purchase machines with more RAM than this, you can launch multiple executors in a single node. In Spark’s standalone mode, a worker is responsible for launching multiple executors according to its available memory and cores, and each executor will be launched in a separate Java VM.

D. Network: In our experience, when the data is in memory, a lot of Spark applications are network-bound. Using a 10 Gigabit or higher network is the best way to make these applications faster. This is especially true for “distributed reduce” applications such as group-bys, reduce-bys, and SQL joins. In any given application, you can see how much data Spark shuffles across the network from the application’s monitoring UI (http://<driver-node>:4040).

E. CPU: Spark scales well to tens of CPU cores per machine because it performs minimal sharing between threads. You should likely provision at least 8-16 cores per machine. Depending on the CPU cost of your workload, you may also need more: once data is in memory, most applications are either CPU- or network-bound.

====================================================



The spark.yarn.driver.memoryOverhead and spark.driver.cores values are derived from the resources of the node that AEL is installed on, under the assumption that only the driver executor is running there. The spark.default.parallelism value is derived from the amount of parallelism per core that is required (an arbitrary setting). In the example above, a value of 36 is derived from a parallelism per core setting of 2, multiplied by the spark.executor.instances, 18.

spark.executor.instances - 18
spark.yarn.executor.memoryOverhead - 1024MiB
spark.executor.memory - 2G
spark.yarn.driver.memoryOverhead - 1024MiB
spark.driver.memory - 3G
spark.executor.cores - 2
spark.driver.cores - 2
spark.default.parallelism - 18 executors * 2 core per executors = 36


==============
Hive Support with PySpark:

hc = HiveContext(sc)

hc.sql("select * from db_name.table_name limit 5").show()

self.spark = SparkSession.builder.appName(self.appname).enableHiveSupport().getOrCreate()
self.sc = self.spark.sparkContext
self.spark.conf.set("hive.exec.dynamic.partition", "true")
self.spark.conf.set("hive.exec.dynamic.partition.mode" , "nonstrict")
#self.spark.conf.set("spark.sql.sources.partitionOverwriteMode", "dynamic")
self.spark.conf.set("hive.merge.tezfiles" , "true")
self.spark.conf.set("hive.merge.mapfiles" , "true")
self.spark.conf.set("hive.merge.mapredfiles" , "true")
self.spark.conf.set("hive.merge.size.per.task" , "128000000")
self.spark.conf.set("hive.merge.smallfiles.avgsize" , "128000000")


spark.sql("select * from db_name.table_name limit 5").show()

dblist = spark.catalog._jcatalog.listDatabases()
dblist.createOrReplaceTempView("dblist")
spark.sql("select name from dblist where name ='dbname'").count()

tbllist = self.spark.catalog._jcatalog.listTables("dbname")
tbllist.createOrReplaceTempView("tbllist")
self.spark.sql("select name from tbllist where name =''").count()


df.write.saveAsTable('global_shared.test_beepz')
spark.table('temp_table_name').write.saveAsTable('db_name.table_name')

=======
to check the partition row count
from pyspark.sql.functions import spark_partition_id, asc, desc
df\
    .withColumn("partitionId", spark_partition_id())\
    .groupBy("partitionId")\
    .count()\
    .orderBy(asc("count"))\
    .show()
=====

For pyspark, you have to access the hidden _jdf and jSparkSession variables, since the Python objects do not expose the needed attributes directly... 
df.cache().foreach(lambda x: x) 
catalyst_plan = df._jdf.queryExecution().logical() 
spark._jsparkSession.sessionState().executePlan(catalyst_plan).optimizedPlan().stats().sizeInBytes()

====
to write into parquet
spark.write.parquet('hdfs')

parquet-tools cat --json  hdfs://localhost/tmp/save/part-r-00000-6a3ccfae-5eb9-4a88-8ce8-b11b2644d5de.gz.parquet
parquet-tools csv input.gz.parquet | csvq -f json "select id, description" 

parquet-cli
=====================
cassandra integration with pyspark
-------
pyspark --packages com.datastax.spark:spark-cassandra-connector_2.12:3.2.0 \
  --jars /hadoopData/bdipoc/poc/python/beepz/cassandra_connect/joda-time-2.1.jar \
  --conf spark.sql.extensions=com.datastax.spark.connector.CassandraSparkExtensions \
  --conf spark.jars.ivy=/hadoopData/bdipoc/poc/python/beepz/cassandra_jars \
  --conf spark.files=/hadoopData/bdipoc/poc/python/beepz/cassandra_connect/secure-connect-fcc-tutorial.zip \
  --conf spark.cassandra.connection.config.cloud.path=secure-connect-fcc-tutorial.zip \
  --conf spark.cassandra.auth.username="uTaRSyTMKLOGhMiKZoCrzZoL" \
  --conf spark.cassandra.auth.password="iA5-sxJn,B,YSBky6-1,2-jZLLLXC6fevNd9XGyI1htg-lAwPLRO7bZ,PoxIeLIl0-G7mgnjJG_Sn_hrzH5A_jn+l9xPRpKDkRJ2gx+t3C4wtDmuZ1CIZ36bBgWkjcZ3" \
  --conf spark.dse.continuousPagingEnabled=false

read:
=======
df = spark.read\
    .format("org.apache.spark.sql.cassandra")\
    .options(table="restaurent", keyspace="tabular")\
    .load()


write:
=======
new_df.write\
    .format("org.apache.spark.sql.cassandra")\
    .mode('append')\
    .options(table="restaurent", keyspace="tabular")\
    .save()


